{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MTL_classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONZcCEVavzKCU8lzT9tnpL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IIF0403/Project/blob/master/MTL_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6Hvc5DsYors"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import copy\n",
        "import sys"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN_ZXcF0NY_l",
        "outputId": "845a4fda-7d29-4ca3-a432-947ec25bdfae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "seed1 = 14\n",
        "seed2 = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Function loads data from csv and removes labels from y_train\n",
        "def prepare_data(Dataset, test_data_size=0.2, unlabeled_data_size = 0.9 ):\n",
        "  url_raw = 'https://raw.githubusercontent.com/IIF0403/timeseries/master/data/' \n",
        "  \n",
        "  url_train = url_raw + Dataset+'/'+Dataset+'_TRAIN'\n",
        "  url_test = url_raw + Dataset+'/'+Dataset+'_TEST'\n",
        "\n",
        "  data_train = pd.read_csv(url_train,header=None)\n",
        "  data_test = pd.read_csv(url_test, header=None)\n",
        "\n",
        "  #Split data into 80% train data and 20% test data\n",
        "  data = pd.concat((data_train, data_test)) \n",
        "  data_train, data_test = train_test_split(data, test_size=test_data_size, random_state=seed1)\n",
        "\n",
        "  #Some of the datasets has classes starting from 1, need them to start from 0\n",
        "  if ( ((data_train.iloc[:,0]==0).sum())==0 ): #If there is no class 0\n",
        "    data_train.iloc[:,0] = data_train.iloc[:,0]-1\n",
        "    data_test.iloc[:,0] = data_test.iloc[:,0]-1\n",
        "  \n",
        "  #Split the train data into 90% unlabeled data and 10% labeled data\n",
        "  train_labeled, train_unlabeled = train_test_split(data_train, test_size=unlabeled_data_size, random_state=seed2)  \n",
        "  train_unlabeled[train_unlabeled.columns[0]]=-1 #Set labels to -1\n",
        "  train = pd.concat((train_labeled,train_unlabeled))\n",
        "  data_train = train.sample(frac = 1)  #shuffle the data\n",
        "\n",
        "  x_train = data_train.iloc[:,1:].to_numpy()\n",
        "  y_train = data_train.iloc[:,0].to_numpy()\n",
        "  x_test = data_test.iloc[:,1:].to_numpy()\n",
        "  y_test = data_test.iloc[:,0].to_numpy() \n",
        "\n",
        "  x_train=x_train[:,np.newaxis,:] \n",
        "  x_test=x_test[:,np.newaxis,:]\n",
        "\n",
        "\n",
        "  #Torch\n",
        "  x_train = torch.from_numpy(x_train).to(device)\n",
        "  y_train = torch.from_numpy(y_train).to(device)\n",
        "  x_test = torch.from_numpy(x_test).to(device)\n",
        "  y_test = torch.from_numpy(y_test).to(device)\n",
        "\n",
        "  return x_train, y_train, x_test, y_test\n",
        "\n",
        "x_train, y_train, x_test, y_test = prepare_data(Dataset)\n",
        "\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPYJkrNPWQdR",
        "outputId": "ab0a7e5c-4470-4574-ac5d-927a25ed0c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "#Dataset = \"Coffee\"\n",
        "Dataset = \"CBF\"\n",
        "#Dataset = \"FaceFour\"\n",
        "\n",
        "x_train, y_train, x_test, y_test = prepare_data(Dataset)\n",
        "\n",
        "classes = len(np.unique(y_test))\n",
        "T = x_train.shape[2]\n",
        "\n",
        "print(\"x_train shape: \", x_train.shape, \"  y_train shape: \",x_train.shape)\n",
        "print(\"x_test shape: \", x_test.shape, \"  y_test shape: \",x_test.shape)\n",
        "print(\"#classes: \",classes)\n",
        "print(\"#data points in each time series: \", T)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape:  torch.Size([744, 1, 128])   y_train shape:  torch.Size([744, 1, 128])\n",
            "x_test shape:  torch.Size([186, 1, 128])   y_test shape:  torch.Size([186, 1, 128])\n",
            "#classes:  3\n",
            "#data points in each time series:  128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOdlUl7i3-Ln"
      },
      "source": [
        "class MTL(nn.Module):\n",
        "  def __init__(self, horizon):\n",
        "    super(MTL, self).__init__()\n",
        "    self.conv1 = nn.Conv1d(x_train.shape[1], 128, 9, padding=(9 // 2))\n",
        "    self.bnorm1 = nn.BatchNorm1d(128)        \n",
        "    self.conv2 = nn.Conv1d(128, 256, 5, padding=(5 // 2))\n",
        "    self.bnorm2 = nn.BatchNorm1d(256)\n",
        "    self.conv3 = nn.Conv1d(256, 128, 3, padding=(3 // 2))\n",
        "    self.bnorm3 = nn.BatchNorm1d(128)        \n",
        "    self.classification_head = nn.Linear(128, classes)\n",
        "    self.forecasting_head = nn.Linear(128, horizon)\n",
        "\n",
        "  def forward(self, x_class, x_forecast):\n",
        "    b1_class = F.relu(self.bnorm1(self.conv1(x_class)))\n",
        "    b2_class = F.relu(self.bnorm2(self.conv2(b1_class)))\n",
        "    b3_class = F.relu(self.bnorm3(self.conv3(b2_class)))\n",
        "\n",
        "    b1_forecast = F.relu(self.bnorm1(self.conv1(x_forecast)))\n",
        "    b2_forecast = F.relu(self.bnorm2(self.conv2(b1_forecast)))\n",
        "    b3_forecast = F.relu(self.bnorm3(self.conv3(b2_forecast)))\n",
        "        \n",
        "    features_class = torch.mean(b3_class, 2)\n",
        "    features_forecast = torch.mean(b3_forecast, 2)\n",
        "        \n",
        "    out_class = self.classification_head(features_class)\n",
        "    out_forecast = self.forecasting_head(features_forecast)\n",
        "\n",
        "    return out_class, out_forecast\n",
        "\n",
        "  def forward_test(self, x_class):\n",
        "    b1_class = F.relu(self.bnorm1(self.conv1(x_class)))\n",
        "    b2_class = F.relu(self.bnorm2(self.conv2(b1_class)))\n",
        "    b3_class = F.relu(self.bnorm3(self.conv3(b2_class)))\n",
        "\n",
        "    features_class = torch.mean(b3_class, 2)\n",
        "    out_class =self.classification_head(features_class)\n",
        "    return out_class\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRcSVFOEkJ69"
      },
      "source": [
        "stride = 0.2\n",
        "horizon = 0.2\n",
        "alpha = 0.1\n",
        "\n",
        "\n",
        "\n",
        "MTL_net = MTL(int(T*horizon)).to(device)\n",
        "\n",
        "\n",
        "#Loss functions and optimizer\n",
        "loss_func_class = nn.CrossEntropyLoss()\n",
        "loss_func_forecast = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(MTL_net.parameters(), lr=1e-4)\n",
        "\n",
        "def optimize(x_labeled, y_labeled, x_forecast, y_forecast):\n",
        "  y_hat_class, y_hat_forecast = MTL_net(x_labeled.float(), x_forecast.float())\n",
        "  \n",
        "  loss_class = loss_func_class(y_hat_class, y_labeled)\n",
        "  loss_forecast = loss_func_forecast(y_hat_forecast, torch.squeeze(y_forecast).float() )\n",
        "    \n",
        "  loss_MTL = loss_class + alpha*loss_forecast\n",
        "  optimizer.zero_grad()\n",
        "  loss_MTL.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return loss_class.item(), loss_forecast.item()\n",
        "\n",
        "\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yabsRKIm9ca7"
      },
      "source": [
        "#Function to shuffle data\n",
        "def shuffle(X,Y):\n",
        "  index = np.array( [int(i) for i in range(x_train.shape[0]) ] )\n",
        "  np.random.shuffle(index)\n",
        "  return X[index], Y[index]\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a_uq1yQPIPO"
      },
      "source": [
        "def sliding_window(X, stride, horizon):\n",
        "  T = X.shape[2] #number of datapoints in each time series\n",
        "\n",
        "  s = int(stride* T) #stride\n",
        "  h = int(horizon* T) #horizon\n",
        "\n",
        "  X_F = [] \n",
        "  Y_F = []\n",
        "\n",
        "  for i in range(0, T, s):\n",
        "    if (i+2*h <= T):\n",
        "      xf_i = X[:,:, i:i+h]\n",
        "      yf_i = X[:,:, i+h:i+2*h ]\n",
        "\n",
        "      X_F.append(xf_i)\n",
        "      Y_F.append(yf_i)\n",
        "  \n",
        "  return torch.cat(X_F), torch.cat(Y_F)\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk57LH02ZgHQ"
      },
      "source": [
        "X_F, Y_F = sliding_window(x_train, stride, horizon)\n",
        "\n",
        "batch_size = 35\n",
        "max_epochs = 5000\n",
        "\n",
        "accuracies = []\n",
        "losses_class = []\n",
        "losses_forecast = []\n",
        "\n",
        "for e in range(max_epochs):\n",
        "  #Shuffle data\n",
        "  x_train, y_train = shuffle(x_train,y_train)\n",
        "  X_F, Y_F = shuffle(X_F, Y_F)\n",
        "\n",
        "  x_train_labeled = x_train[y_train!=-1] #the x part of the training set that has a label\n",
        "  y_train_labeled = y_train[y_train!=-1] #the y part of the training set that has a label\n",
        "\n",
        "  for i in range(0, X_F.shape[0], batch_size):\n",
        "    if (i+batch_size <= X_F.shape[0]):\n",
        "      x_forecast = X_F[i:i+batch_size]\n",
        "      y_forecast = Y_F[i:i+batch_size]\n",
        "    else:\n",
        "      x_forecast = X_F[i:]\n",
        "      y_forecast = Y_F[i:]\n",
        "    \n",
        "    loss_class, loss_forecast = optimize(x_train_labeled, y_train_labeled, x_forecast, y_forecast)\n",
        "    losses_class.append(loss_class)\n",
        "    losses_forecast.append(loss_forecast)\n",
        "\n",
        "  y_hat_class = MTL_net.forward_test(x_test.float())\n",
        "  predicted = torch.max(y_hat_class,1)[1]\n",
        "  #print(\"Predicted: \", predicted)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, predicted) \n",
        "  accuracies.append(accuracy)\n",
        "\n",
        "  avg_loss_class = np.mean(losses_class)\n",
        "  avg_loss_forecast = np.mean(losses_forecast)\n",
        "\n",
        "  print(\"Epoch: \",e, \"  Accuracy: \",accuracy,\" Avg loss classification: \", avg_loss_class , \"  Avg loss forecast: \", avg_loss_forecast)\n",
        "\n",
        "  if accuracy==1.0:\n",
        "    break;\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}