{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MTL_classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONZcCEVavzKCU8lzT9tnpL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IIF0403/Project/blob/master/MTL_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6Hvc5DsYors"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import copy\n",
        "import sys"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN_ZXcF0NY_l",
        "outputId": "47844404-4719-475c-9911-d1c39af2b038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "seed1 = 14\n",
        "seed2 = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Function loads data from csv and removes labels from y_train\n",
        "def prepare_data(Dataset, test_data_size=0.2, unlabeled_data_size = 0.9 ):\n",
        "  url_raw = 'https://raw.githubusercontent.com/IIF0403/timeseries/master/data/' \n",
        "  \n",
        "  url_train = url_raw + Dataset+'/'+Dataset+'_TRAIN'\n",
        "  url_test = url_raw + Dataset+'/'+Dataset+'_TEST'\n",
        "\n",
        "  data_train = pd.read_csv(url_train,header=None)\n",
        "  data_test = pd.read_csv(url_test, header=None)\n",
        "\n",
        "  #Split data into 80% train data and 20% test data\n",
        "  data = pd.concat((data_train, data_test)) \n",
        "  data_train, data_test = train_test_split(data, test_size=test_data_size, random_state=seed1)\n",
        "\n",
        "  #Some of the datasets has classes starting from 1, need them to start from 0\n",
        "  if ( ((data_train.iloc[:,0]==0).sum())==0 ): #If there is no class 0\n",
        "    data_train.iloc[:,0] = data_train.iloc[:,0]-1\n",
        "    data_test.iloc[:,0] = data_test.iloc[:,0]-1\n",
        "  \n",
        "  #Split the train data into 90% unlabeled data and 10% labeled data\n",
        "  train_labeled, train_unlabeled = train_test_split(data_train, test_size=unlabeled_data_size, random_state=seed2)  \n",
        "  train_unlabeled[train_unlabeled.columns[0]]=-1 #Set labels to -1\n",
        "  train = pd.concat((train_labeled,train_unlabeled))\n",
        "  data_train = train.sample(frac = 1)  #shuffle the data\n",
        "\n",
        "  x_train = data_train.iloc[:,1:].to_numpy()\n",
        "  y_train = data_train.iloc[:,0].to_numpy()\n",
        "  x_test = data_test.iloc[:,1:].to_numpy()\n",
        "  y_test = data_test.iloc[:,0].to_numpy() \n",
        "\n",
        "  x_train=x_train[:,np.newaxis,:] \n",
        "  x_test=x_test[:,np.newaxis,:]\n",
        "\n",
        "\n",
        "  #Torch\n",
        "  x_train = torch.from_numpy(x_train).to(device)\n",
        "  y_train = torch.from_numpy(y_train).to(device)\n",
        "  x_test = torch.from_numpy(x_test).to(device)\n",
        "  y_test = torch.from_numpy(y_test).to(device)\n",
        "\n",
        "  return x_train, y_train, x_test, y_test\n",
        "\n",
        "x_train, y_train, x_test, y_test = prepare_data(Dataset)\n",
        "\n",
        "\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPYJkrNPWQdR",
        "outputId": "6aef0044-1f8e-4d3a-837e-2894feb9fcce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "#Dataset = \"Coffee\"\n",
        "Dataset = \"CBF\"\n",
        "#Dataset = \"FaceFour\"\n",
        "\n",
        "x_train, y_train, x_test, y_test = prepare_data(Dataset)\n",
        "\n",
        "classes = len(np.unique(y_test))\n",
        "T = x_train.shape[2]\n",
        "\n",
        "print(\"x_train shape: \", x_train.shape, \"  y_train shape: \",x_train.shape)\n",
        "print(\"x_test shape: \", x_test.shape, \"  y_test shape: \",x_test.shape)\n",
        "print(\"#classes: \",classes)\n",
        "print(\"#data points in each time series: \", T)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape:  torch.Size([744, 1, 128])   y_train shape:  torch.Size([744, 1, 128])\n",
            "x_test shape:  torch.Size([186, 1, 128])   y_test shape:  torch.Size([186, 1, 128])\n",
            "#classes:  3\n",
            "#data points in each time series:  128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOdlUl7i3-Ln"
      },
      "source": [
        "class MTL(nn.Module):\n",
        "  def __init__(self, horizon):\n",
        "    super(MTL, self).__init__()\n",
        "    self.conv1 = nn.Conv1d(x_train.shape[1], 128, 9, padding=(9 // 2))\n",
        "    self.bnorm1 = nn.BatchNorm1d(128)        \n",
        "    self.conv2 = nn.Conv1d(128, 256, 5, padding=(5 // 2))\n",
        "    self.bnorm2 = nn.BatchNorm1d(256)\n",
        "    self.conv3 = nn.Conv1d(256, 128, 3, padding=(3 // 2))\n",
        "    self.bnorm3 = nn.BatchNorm1d(128)        \n",
        "    self.classification_head = nn.Linear(128, classes)\n",
        "    self.forecasting_head = nn.Linear(128, horizon)\n",
        "\n",
        "  def forward(self, x_class, x_forecast):\n",
        "    b1_class = F.relu(self.bnorm1(self.conv1(x_class)))\n",
        "    b2_class = F.relu(self.bnorm2(self.conv2(b1_class)))\n",
        "    b3_class = F.relu(self.bnorm3(self.conv3(b2_class)))\n",
        "\n",
        "    b1_forecast = F.relu(self.bnorm1(self.conv1(x_forecast)))\n",
        "    b2_forecast = F.relu(self.bnorm2(self.conv2(b1_forecast)))\n",
        "    b3_forecast = F.relu(self.bnorm3(self.conv3(b2_forecast)))\n",
        "        \n",
        "    features_class = torch.mean(b3_class, 2)\n",
        "    features_forecast = torch.mean(b3_forecast, 2)\n",
        "        \n",
        "    out_class = self.classification_head(features_class)\n",
        "    out_forecast = self.forecasting_head(features_forecast)\n",
        "\n",
        "    return out_class, out_forecast\n",
        "\n",
        "  def forward_test(self, x_class):\n",
        "    b1_class = F.relu(self.bnorm1(self.conv1(x_class)))\n",
        "    b2_class = F.relu(self.bnorm2(self.conv2(b1_class)))\n",
        "    b3_class = F.relu(self.bnorm3(self.conv3(b2_class)))\n",
        "\n",
        "    features_class = torch.mean(b3_class, 2)\n",
        "    out_class =self.classification_head(features_class)\n",
        "    return out_class\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRcSVFOEkJ69"
      },
      "source": [
        "stride = 0.2\n",
        "horizon = 0.2\n",
        "alpha = 0.1\n",
        "\n",
        "\n",
        "\n",
        "MTL_net = MTL(int(T*horizon)).to(device)\n",
        "\n",
        "\n",
        "#Loss functions and optimizer\n",
        "loss_func_class = nn.CrossEntropyLoss()\n",
        "loss_func_forecast = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(MTL_net.parameters(), lr=1e-4)\n",
        "\n",
        "def optimize(x_labeled, y_labeled, x_forecast, y_forecast):\n",
        "  y_hat_class, y_hat_forecast = MTL_net(x_labeled.float(), x_forecast.float())\n",
        "  \n",
        "  loss_class = loss_func_class(y_hat_class, y_labeled)\n",
        "  loss_forecast = loss_func_forecast(y_hat_forecast, torch.squeeze(y_forecast).float() )\n",
        "    \n",
        "  loss_MTL = loss_class + alpha*loss_forecast\n",
        "  optimizer.zero_grad()\n",
        "  loss_MTL.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return loss_class.item(), loss_forecast.item()\n",
        "\n",
        "\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yabsRKIm9ca7"
      },
      "source": [
        "#Function to shuffle data\n",
        "def shuffle(X,Y):\n",
        "  index = np.array( [int(i) for i in range(x_train.shape[0]) ] )\n",
        "  np.random.shuffle(index)\n",
        "  return X[index], Y[index]\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a_uq1yQPIPO"
      },
      "source": [
        "def sliding_window(X, stride, horizon):\n",
        "  T = X.shape[2] #number of datapoints in each time series\n",
        "\n",
        "  s = int(stride* T) #stride\n",
        "  h = int(horizon* T) #horizon\n",
        "\n",
        "  X_F = [] \n",
        "  Y_F = []\n",
        "\n",
        "  for i in range(0, T, s):\n",
        "    if (i+2*h <= T):\n",
        "      xf_i = X[:,:, i:i+h]\n",
        "      yf_i = X[:,:, i+h:i+2*h ]\n",
        "\n",
        "      X_F.append(xf_i)\n",
        "      Y_F.append(yf_i)\n",
        "  \n",
        "  return torch.cat(X_F), torch.cat(Y_F)\n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk57LH02ZgHQ",
        "outputId": "fd886100-1fb2-40ef-8fbd-5a24e1f8f700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "X_F, Y_F = sliding_window(x_train, stride, horizon)\n",
        "\n",
        "batch_size = 35\n",
        "max_epochs = 5000\n",
        "\n",
        "accuracies = []\n",
        "losses_class = []\n",
        "losses_forecast = []\n",
        "\n",
        "for e in range(max_epochs):\n",
        "  #Shuffle data\n",
        "  x_train, y_train = shuffle(x_train,y_train)\n",
        "  X_F, Y_F = shuffle(X_F, Y_F)\n",
        "\n",
        "  x_train_labeled = x_train[y_train!=-1] #the x part of the training set that has a label\n",
        "  y_train_labeled = y_train[y_train!=-1] #the y part of the training set that has a label\n",
        "\n",
        "  for i in range(0, X_F.shape[0], batch_size):\n",
        "    if (i+batch_size <= X_F.shape[0]):\n",
        "      x_forecast = X_F[i:i+batch_size]\n",
        "      y_forecast = Y_F[i:i+batch_size]\n",
        "    else:\n",
        "      x_forecast = X_F[i:]\n",
        "      y_forecast = Y_F[i:]\n",
        "    \n",
        "    loss_class, loss_forecast = optimize(x_train_labeled, y_train_labeled, x_forecast, y_forecast)\n",
        "    losses_class.append(loss_class)\n",
        "    losses_forecast.append(loss_forecast)\n",
        "\n",
        "  y_hat_class = MTL_net.forward_test(x_test.float())\n",
        "  predicted = torch.max(y_hat_class,1)[1]\n",
        "  #print(\"Predicted: \", predicted)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, predicted) \n",
        "  accuracies.append(accuracy)\n",
        "\n",
        "  avg_loss_class = np.mean(losses_class)\n",
        "  avg_loss_forecast = np.mean(losses_forecast)\n",
        "\n",
        "  print(\"Epoch: \",e, \"  Accuracy: \",accuracy,\" Avg loss classification: \", avg_loss_class , \"  Avg loss forecast: \", avg_loss_forecast)\n",
        "\n",
        "  if accuracy==1.0:\n",
        "    break;\n",
        "\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0   Accuracy:  0.8709677419354839  Avg loss classification:  0.8540634946389631   Avg loss forecast:  1.0612554983659224\n",
            "Epoch:  1   Accuracy:  0.9623655913978495  Avg loss classification:  0.7066489397124811   Avg loss forecast:  1.0142217617143283\n",
            "Epoch:  2   Accuracy:  0.9838709677419355  Avg loss classification:  0.5992139428853989   Avg loss forecast:  0.9641104512142412\n",
            "Epoch:  3   Accuracy:  0.989247311827957  Avg loss classification:  0.518372996117581   Avg loss forecast:  0.9229784052480351\n",
            "Epoch:  4   Accuracy:  0.989247311827957  Avg loss classification:  0.4577312101017345   Avg loss forecast:  0.8897561902349646\n",
            "Epoch:  5   Accuracy:  0.9946236559139785  Avg loss classification:  0.4106214178556746   Avg loss forecast:  0.8631269502820391\n",
            "Epoch:  6   Accuracy:  0.9946236559139785  Avg loss classification:  0.372744717961782   Avg loss forecast:  0.8402783232075828\n",
            "Epoch:  7   Accuracy:  0.9946236559139785  Avg loss classification:  0.3414836131374944   Avg loss forecast:  0.8207651732320135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-26bf8841880f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0my_forecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_F\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mloss_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_forecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_labeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_labeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_forecast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_forecast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mlosses_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mlosses_forecast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_forecast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-8959cb00f620>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(x_labeled, y_labeled, x_forecast, y_forecast)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mloss_MTL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_class\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss_forecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mloss_MTL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}